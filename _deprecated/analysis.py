import os, json, sys, os, csv, statistics, hashlib
import pandas as pd
import numpy as np
from scipy import stats
import networkx as nx
import seaborn as sns
import matplotlib.pyplot as plt
pd.options.mode.chained_assignment = None

sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir))
import config

def space_complexity(graph_filenames):
    for g_file in graph_filenames:
        G = nx.read_graphml(g_file)

        num_nodes = len(G.nodes())
        num_edges = len(G.edges())
        density = nx.density(G)

        num_components = nx.number_strongly_connected_components(G)
        
        indegree = G.in_degree()
        outdegree = G.out_degree()
        in_degrees_values = []
        for indeg in indegree:
            in_degrees_values.append(indeg[1])
        out_degrees_values = []
        for outdeg in outdegree:
            out_degrees_values.append(outdeg[1])

        closeness_centrality = nx.closeness_centrality(G)
        closeness_centr_values = []
        for k_cc in closeness_centrality.keys():
            closeness_centr_values.append(closeness_centrality[k_cc])

        aggregation_level = 0
        if "a0" in g_file: aggregation_level=0
        elif "a1" in g_file: aggregation_level=1
        elif "a2" in g_file: aggregation_level=2
        else: aggregation_level=3

        filter_level = 0
        if "f0" in g_file: filter_level=0
        elif "f1" in g_file: filter_level=1
        elif "f2" in g_file: filter_level=2
        else: filter_level=3

        subfolders =g_file.replace(".graphml","").split("/")
        network_type=subfolders[len(subfolders)-2]
        network_params = network_type.split("_")
        model=subfolders[len(subfolders)-1].split("_")[0]

        n_seed = int(network_params[0].replace("s",""))
        n_host = int(network_params[1].replace("h",""))
        n_vuln = int(network_params[2].replace("v",""))

        with open(config.ANALYSIS_SPACE_FILE, 'a', newline='') as fd:
            writer = csv.writer(fd)
            writer.writerow([
                network_type,n_seed,n_host,n_vuln,model,filter_level,aggregation_level,
                num_nodes,num_edges,density,num_components,
                list(np.quantile(in_degrees_values,[0.25,0.5,0.75])) if len(in_degrees_values)>0 else None,
                list(np.quantile(out_degrees_values,[0.25,0.5,0.75])) if len(out_degrees_values)>0 else None,
                list(np.quantile(closeness_centr_values,[0.25,0.5,0.75])) if len(closeness_centr_values)>0 else None,
                sum(in_degrees_values)/len(in_degrees_values) if len(in_degrees_values)>0 else None,
                sum(out_degrees_values)/len(out_degrees_values) if len(out_degrees_values)>0 else None,
                sum(closeness_centr_values)/len(closeness_centr_values) if len(closeness_centr_values)>0 else None,
            ])

def compute_risk_analysis(vuln_ids, vulns_list):
    base_scores=[]
    impact_scores=[]
    exploit_scores=[]
    for v_curr in vuln_ids:
        for v_gt in vulns_list:
            if v_gt["id"] == v_curr:
                base_scores.append(v_gt["cvss_metrics"]["base"])
                impact_scores.append(v_gt["cvss_metrics"]["impact"])
                exploit_scores.append(v_gt["cvss_metrics"]["exploitability"])
        
    return {
        "impact": max(impact_scores), #statistics.mean(impact_scores), #sum(impacts)/len(impacts),
        "exploit": max(exploit_scores), #statistics.mean(exploit_scores), #sum(likelihoods)/len(likelihoods),
        "score" : max(base_scores), #statistics.mean(base_scores),
    }, {
        "impact": impact_scores, #statistics.mean(impact_scores), #sum(impacts)/len(impacts),
        "exploit": exploit_scores, #statistics.mean(exploit_scores), #sum(likelihoods)/len(likelihoods),
        "score" : base_scores, #statistics.mean(base_scores),
    }, 

def accuracy_complexity(graph_filenames, a3_filename):

    G_base = nx.read_graphml(a3_filename)
    all_paths_distances = {x[0]:x[1] for x in nx.all_pairs_shortest_path_length(G_base)}
    entry_points = {}
    for src in all_paths_distances.keys():
        dict_dist = all_paths_distances[src]
        max_val = max(dict_dist.values())
        dst = [k for k,v in dict_dist.items() if v >= max_val]
        for target in dst:
            entry_points[(src,target)]=max_val
    entry_points = dict(sorted(entry_points.items(), key=lambda x:x[1], reverse=True))

    sources = []
    goals = []
    for entry in entry_points.keys():
        if "@" in entry[0] and "@" in entry[1]:
            sources.append(entry[0])
            goals.append(entry[1])

    all_risk_lists=[]
    for g_conf in graph_filenames:
        g_file = list(g_conf.keys())[0]
        net_file = g_conf[g_file]
        with open(net_file) as net_f:
            inventory_vulns=json.load(net_f)["meta_vulnerabilities"]
        
        G = nx.read_graphml(g_file)
        node_types = nx.get_node_attributes(G,"type")

        subfolders=g_file.replace(".graphml","").split("/")
        network_type=subfolders[len(subfolders)-2]
        model=subfolders[len(subfolders)-1].split("_")[0]

        network_params = network_type.split("_")
        n_seed = int(network_params[0].replace("s",""))
        n_host = int(network_params[1].replace("h",""))
        n_vuln = int(network_params[2].replace("v",""))

        aggregation_level = 0
        if "a0" in g_file: aggregation_level=0
        elif "a1" in g_file: aggregation_level=1
        elif "a2" in g_file: aggregation_level=2
        else: aggregation_level=3

        filter_level = 0
        if "f0" in g_file: filter_level=0
        elif "f1" in g_file: filter_level=1
        elif "f2" in g_file: filter_level=2
        else: filter_level=3

        all_risks=[]
        id_count=1
        for s in sources[:2]: 
            for t in goals[:1]:
                if s not in G.nodes() or t not in G.nodes(): 
                    print("wrong format: ", g_file)
                    break 
                
                current_paths = list(nx.all_simple_paths(G, source=s, target=t))
                vulns_path=[]
                for single_path in current_paths:
                    for node_p in single_path:
                        if node_types[node_p] == "vulnerability":
                            vulns_path.append(node_p)

                # print("file", net_file,"src: ",s," - dst: ",t,"vulns: ",list(set(vulns_path)))

                risk_values, risk_list_values = compute_risk_analysis(vulns_path, inventory_vulns)
                risk_values["id"] = id_count
                all_risks.append(risk_values)

                risk_list_values["network"]=network_type
                risk_list_values["model"]=model
                risk_list_values["filter"]=filter_level
                risk_list_values["aggregation"]=aggregation_level
                risk_list_values["id_path"]=id_count
                all_risk_lists.append(risk_list_values)
                # k_dict = network_type+"#"+model+"#"+str(filter_level)+"#"+str(aggregation_level)+"#"+str(id_count)
                # risk_dict[k_dict] = risk_list_values
                
                id_count+=1

        with open(config.ANALYSIS_ACCURACY_FILE, 'a', newline='') as fd:
            writer = csv.writer(fd)
            for risk_v in all_risks:
                writer.writerow([
                    network_type,n_seed,n_host,n_vuln,model,filter_level,aggregation_level,
                    len(all_risks),risk_v["id"],risk_v["impact"],risk_v["exploit"],risk_v["score"]
                ])

    return pd.DataFrame(all_risk_lists)

def plot_accuracy_paths(graph_filenames, a3_filename):
    
    plt.rcParams.update({'font.size': 14})
    fig, axs = plt.subplots(1, 3)
    fig.set_figwidth(15)
    # fig.set_figheight(4)

    G_base = nx.read_graphml(a3_filename)

    base_host_nodes = []
    for entry in G_base.nodes():
        if "@" in entry:
            base_host_nodes.append(entry)

    for g_conf in graph_filenames:
        g_file = list(g_conf.keys())[0]
        
        G = nx.read_graphml(g_file)

        subfolders=g_file.replace(".graphml","").split("/")
        network_type=subfolders[len(subfolders)-2]
        model=subfolders[len(subfolders)-1].split("_")[0]

        aggregation_level = 0
        if "a0" in g_file: aggregation_level=0
        elif "a1" in g_file: aggregation_level=1
        elif "a2" in g_file: aggregation_level=2
        else: aggregation_level=3

        filter_level = 0
        if "f0" in g_file: filter_level=0
        elif "f1" in g_file: filter_level=1
        elif "f2" in g_file: filter_level=2
        else: filter_level=3


        true_positive=0 #paths that are in real and approximate
        false_negative=0 #paths that are in real, but not in approximate
        false_positive=0 #paths that are NOT in real, but are in approximate
        true_negative=0 #paths that are NOT in real, NOR in approximate

        for s in base_host_nodes: 
            for t in base_host_nodes:
                if s not in G.nodes() or t not in G.nodes(): 
                    break 

                if nx.has_path(G,s,t) and nx.has_path(G_base,s,t): true_positive+=1
                elif nx.has_path(G,s,t) and not nx.has_path(G_base,s,t): false_negative+=1
                elif not nx.has_path(G,s,t) and nx.has_path(G_base,s,t): false_positive+=1
                else: true_negative+=1

        confusion_m = np.matrix([[true_positive, false_positive], [false_negative, true_negative]])
        annot_text = np.matrix([["TP\n"+str(true_positive), "FP\n"+str(false_positive)], ["FN\n"+str(false_negative), "TN\n"+str(true_negative)]])

        if aggregation_level==1: 
            i=0
        elif aggregation_level==2:
            i=1
        elif aggregation_level==3:
            i=2
        else: continue

        sns.heatmap(confusion_m, vmin=0,vmax=700, linewidth=0.5,annot=annot_text,fmt="s",yticklabels=False,xticklabels=False,ax=axs[i],cmap="Blues")
        axs[i].set_title("Aggregation level: "+str(i+1))

        # true_positive=0 #paths that are in real and approximate
        # false_negative=0 #paths that are in real, but not in approximate
        # false_positive=0 #paths that are NOT in real, but are in approximate
        # true_negative=0 #paths that are NOT in real, NOR in approximate

        # g_host_nodes = []
        # for entry_g in G.nodes():
        #     if "@" in entry_g:
        #         g_host_nodes.append(entry_g)
        # for sg in g_host_nodes: 
        #     for tg in g_host_nodes:
        #         if sg not in G_base.nodes() or tg not in G_base.nodes(): 
        #             break 
                
        #         if nx.has_path(G,sg,tg) and nx.has_path(G_base,sg,tg): true_positive+=1
        #         elif nx.has_path(G,sg,tg) and not nx.has_path(G_base,sg,tg): false_negative+=1
        #         elif not nx.has_path(G,sg,tg) and nx.has_path(G_base,sg,tg): false_positive+=1
        #         else: true_negative+=1

        # print("TP:", true_positive, "FP:", false_positive, "FN:", false_negative, "TN:", true_negative)
            
    plt.savefig(config.PLOT_ACCURACY_FOLDER+"matrix"+network_type+"_"+model+".png", bbox_inches='tight')

def plot_space_bars(net_id):
    df = pd.read_csv(config.ANALYSIS_SPACE_FILE)
    df_net = df[df["network"] == net_id]
    
    grouped_by_model = df_net.groupby(by=["model"])
    for model_id, df_model in grouped_by_model:
        df_model = df_model[df_model["filter"] == 0]

        aggregation_levels = list(set(df_model["aggregation"]))
        space_data = {
            'nodes': list(df_model["num_nodes"]),
            'edges': list(df_model["num_edges"]),
            'strong components': list(df_model["num_strong_components"]),
        }

        x = np.arange(len(aggregation_levels))  # the label locations
        width = 0.25  # the width of the bars
        multiplier = 0

        fig, ax = plt.subplots(layout='constrained')

        for key, val in space_data.items():
            offset = width * multiplier
            rects = ax.bar(x + offset, val, width, label=key)
            ax.bar_label(rects, padding=3)
            multiplier += 1

        # Add some text for labels, title and custom x-axis tick labels, etc.
        ax.set_xlabel('Aggregation Levels')
        ax.set_title(net_id.replace("_filter_aggregation","") + " - " + model_id)
        ax.set_xticks(x + width, aggregation_levels)
        ax.legend(loc='upper right')

        plt.savefig(config.PLOT_SPACE_FOLDER+net_id+"_"+model_id+".png", bbox_inches='tight')
        plt.close()

def plot_accuracy_bars(net_id):
    df = pd.read_csv(config.ANALYSIS_ACCURACY_FILE)
    df_net = df[df["network"] == net_id]

    risk_plots = ["score","impact","exploit"]
    
    grouped_by_model = df_net.groupby(by=["model"])
    for model_id, df_model in grouped_by_model:
        df_model = df_model[df_model["filter"] == 0]

        fig, axs = plt.subplots(3, 1, layout='constrained')
        fig.set_figwidth(8)
        fig.set_figheight(10)

        for i in range(0,len(risk_plots)):
            id_paths = list(set(df_model["id_path"]))
            risk_name=risk_plots[i]
            aggregation_level_data = {
                '0': list(df_model[df_model["aggregation"] == 0][risk_name]),
                '1': list(df_model[df_model["aggregation"] == 1][risk_name]),
                '2': list(df_model[df_model["aggregation"] == 2][risk_name]),
                '3': list(df_model[df_model["aggregation"] == 3][risk_name]),
            }

            x = np.arange(len(id_paths))  # the label locations
            width = 0.15  # the width of the bars
            multiplier = 0

            for key, val in aggregation_level_data.items():
                offset = width * multiplier
                rects = axs[i].bar(x + offset, val, width, label=key)
                axs[i].bar_label(rects, padding=3)
                multiplier += 1

            if i==0: axs[i].legend(title="aggregation levels", loc='upper left', bbox_to_anchor=(-0.3,0.9))
            if i==2: axs[i].set_xlabel('Paths') 
            axs[i].set_title(risk_name)
            axs[i].set_xticks(x + width, id_paths)
        

        fig.suptitle(net_id.replace("_filter_aggregation","") + " - " + model_id)
        plt.savefig(config.PLOT_ACCURACY_FOLDER+net_id+"_"+model_id+".png", bbox_inches='tight')
        plt.close()

def plot_accuracy_distro(df_risk):
    
    colors_aggregation={
    "0":"#abdda4",
    "1":"#2b83ba",
    "2":"#fdae61",
    "3":"#d7191c"
    }

    risk_plots = ["score","impact","exploit"]
    fig, axs = plt.subplots(3, 1, layout='constrained')
    fig.set_figwidth(8)
    fig.set_figheight(10)

    grouped_by_network = df_risk.groupby(by=["network"])
    for net_id, df_net in grouped_by_network:
        grouped_by_model = df_net.groupby(by=["model"])
        for model_id, df_model in grouped_by_model:
            df_model = df_model[df_model["filter"] == 0]

            width = 0.1
            for i in range(0,len(risk_plots)):
                id_paths = list(set(df_model["id_path"]))
                risk_name=risk_plots[i]

                labels_path=[]
                for id_p in id_paths:
                    df_model_path = df_model[df_model["id_path"] == id_p]
                    aggregation_level_data = {
                        '0': list(df_model_path[df_model_path["aggregation"] == 0][risk_name]),
                        '1': list(df_model_path[df_model_path["aggregation"] == 1][risk_name]),
                        '2': list(df_model_path[df_model_path["aggregation"] == 2][risk_name]),
                        '3': list(df_model_path[df_model_path["aggregation"] == 3][risk_name]),
                    }

                    x=int(id_p)
                    offset = width# * multiplier
                    
                    axs[i].boxplot(aggregation_level_data["0"], positions=[x+(-2)*offset],widths=width,patch_artist=True,boxprops=dict(facecolor=colors_aggregation["0"]),medianprops=dict(color="#000000"))
                    axs[i].boxplot(aggregation_level_data["1"], positions=[x+(-1)*offset],widths=width,patch_artist=True,boxprops=dict(facecolor=colors_aggregation["1"]),medianprops=dict(color="#000000"))
                    axs[i].boxplot(aggregation_level_data["2"], positions=[x+(1)*offset],widths=width,patch_artist=True,boxprops=dict(facecolor=colors_aggregation["2"]),medianprops=dict(color="#000000"))
                    axs[i].boxplot(aggregation_level_data["3"], positions=[x+(2)*offset],widths=width,patch_artist=True,boxprops=dict(facecolor=colors_aggregation["3"]),medianprops=dict(color="#000000"))

                    labels_path.append(str(id_p))

                labels_legend = list(colors_aggregation.keys())
                legend_lines = [plt.Line2D([0], [0], color=colors_aggregation["0"], lw=2),
                                plt.Line2D([0], [0], color=colors_aggregation["1"], lw=2),
                                plt.Line2D([0], [0], color=colors_aggregation["2"], lw=2),
                                plt.Line2D([0], [0], color=colors_aggregation["3"], lw=2)]
                axs[i].legend(legend_lines, labels_legend,title="Aggr. level")

                axs[i].set_xticks(id_paths)
                axs[i].set_xticklabels(labels_path)
                axs[i].set_ylabel(risk_name)
            
    fig.suptitle(net_id.replace("_filter_aggregation","") + " - " + model_id)
    plt.savefig(config.PLOT_ACCURACY_FOLDER+"distro_"+net_id+"_"+model_id+".png", bbox_inches='tight')
    plt.close()

def fill_missing_accuracy(network):
    df = pd.read_csv(config.ANALYSIS_ACCURACY_FILE)

    filter_levels=list(set(df["filter"]))
    aggregation_levels=list(set(df["aggregation"]))
    num_replicas=list(set(df["id_path"]))

    missing_aggregation_levels=[]
    for aggr_l in [0,1,2,3]:
        if aggr_l not in aggregation_levels: missing_aggregation_levels.append(aggr_l)

    with open(config.ANALYSIS_ACCURACY_FILE, 'a', newline='') as fd:
        writer = csv.writer(fd)
        for aggregation in missing_aggregation_levels:
            for elem in num_replicas:
                writer.writerow([
                    network,list(df["model"])[0],0,aggregation,
                    0,elem,0,0,0
                ])

def plot_generation_time(network_id):
    df = pd.read_csv(config.ANALYSIS_TIME_FILE)
    df_net = df[df["network"] == network_id]
    models_list = list(set(df_net["model"]))

    grouped_by_aggregation= df_net.groupby(by=["aggregation"])
    aggregation_levels = list(set(df_net["aggregation"]))
    time_data = {}
    for aggr_level, df_aggr in grouped_by_aggregation:
        df_aggr = df_aggr[df_aggr["filter"] == 0]

        for model_id in models_list:
            if model_id not in time_data.keys(): time_data[model_id] = list(round(df_aggr[df_aggr["model"] == model_id]["generation_time"],3))
            else: time_data[model_id]+=list(round(df_aggr[df_aggr["model"] == model_id]["generation_time"],3))
            

    x = np.arange(len(aggregation_levels))  # the label locations
    width = 0.25  # the width of the bars
    multiplier = 0

    fig, ax = plt.subplots(layout='constrained')
    fig.set_figwidth(8)
    fig.set_figheight(8)

    for key, val in time_data.items():
        offset = width * multiplier
        rects = ax.bar(x + offset, val, width, label=key)
        ax.bar_label(rects, padding=3)
        multiplier += 1

    # Add some text for labels, title and custom x-axis tick labels, etc.
    ax.set_xlabel('Aggregation Levels')
    ax.set_title(network_id.replace("_filter_aggregation",""))
    ax.set_xticks(x + width, aggregation_levels)
    ax.set_ylabel("Generation time (s)")
    ax.legend(loc='upper right')

    plt.savefig(config.PLOT_TIME_FOLDER+network_id+".png", bbox_inches='tight')
    plt.close()

def plot_generation_time_trend():
    df = pd.read_csv(config.ANALYSIS_TIME_FILE)

    plt.rcParams.update({'font.size': 22})
    fig, axs = plt.subplots(3, 1)
    fig.set_figwidth(18)
    fig.set_figheight(18)

    i=0
    grouped_by_model = df.groupby(by=["model"])
    for model_id, df_model in grouped_by_model:
        grouped_by_network = df_model.groupby(by=["network"])
        
        x_vals=[]
        y_vals={}
        for net_id, df_net in grouped_by_network:
            if "real" in net_id: continue
            df_net = df_net[df_net["filter"] == 0]

            net_params = net_id.split("_")
            n_host = int(net_params[1].replace("h",""))
            n_vuln = int(net_params[2].replace("v",""))

            x_vals.append(n_host)
            for aggregation_level in [0,1,2,3]:
                val_time = df_net[df_net["aggregation"] == aggregation_level]["generation_time"]
                if aggregation_level not in y_vals.keys():  y_vals[aggregation_level] = [val_time]
                else: y_vals[aggregation_level].append(val_time)
        
        for aggregation_level in [0,1,2,3]:
            axs[i].plot(x_vals, y_vals[aggregation_level], label = str(aggregation_level), linewidth = '3')
        
        axs[i].set_xlabel("num hosts")
        axs[i].set_ylabel("time (s)")
        axs[i].legend(title="Agg. levels")
        axs[i].set_title(model_id, y=0.9)
        i+=1

    plt.savefig(config.PLOT_TIME_FOLDER+"time_trend.png", bbox_inches='tight')


if __name__ == "__main__":
    
    if not os.path.exists("analysis/"): os.mkdir("analysis/")
    if not os.path.exists(config.PLOT_FOLDER): os.mkdir(config.PLOT_FOLDER)
    if not os.path.exists(config.PLOT_SPACE_FOLDER): os.mkdir(config.PLOT_SPACE_FOLDER)
    if not os.path.exists(config.PLOT_TIME_FOLDER): os.mkdir(config.PLOT_TIME_FOLDER)
    if not os.path.exists(config.PLOT_ACCURACY_FOLDER): os.mkdir(config.PLOT_ACCURACY_FOLDER)
    
    reset_space=True
    if not os.path.exists(config.ANALYSIS_SPACE_FILE) or reset_space:
        with open(config.ANALYSIS_SPACE_FILE, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['network','seed','hosts','vulns','model','filter','aggregation',
                             'num_nodes','num_edges','density',
                             'num_strong_components',
                             'indegree','outdegree','close_centrality',
                             'avg_indegree','avg_outdegree','avg_close_centrality'
                            ])
    
    reset_accuracy=True
    if not os.path.exists(config.ANALYSIS_ACCURACY_FILE) or reset_accuracy:
        with open(config.ANALYSIS_ACCURACY_FILE, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['network','seed','hosts','vulns','model','filter','aggregation',
                             'num_paths',"id_path","impact","exploit","score"
                            ])

    for network_context in os.listdir(config.GRAPH_FOLDER):
        if "real" in network_context: continue
        filenames=[]
        
        filenames_netspa=[]
        reference_file_netspa_a3=""
        reference_file_netspa_a0=""
        
        filenames_tva=[]
        reference_file_tva_a3=""
        reference_file_tva_a0=""
        
        filenames_multi=[]
        reference_file_multi_a3=""
        reference_file_multi_a0=""
        for graph_file in os.listdir(config.GRAPH_FOLDER+network_context):
            filenames.append(config.GRAPH_FOLDER+network_context+"/"+graph_file)
            
            if "NETSPA_f0" in graph_file:
                filenames_netspa.append({config.GRAPH_FOLDER+network_context+"/"+graph_file:config.NETWORK_FOLDER+network_context+"/"+graph_file.split("_")[1].replace("graphml","json")})
            if "NETSPA_f0-a3" in graph_file: reference_file_netspa_a3 = config.GRAPH_FOLDER+network_context+"/"+graph_file
            if "NETSPA_f0-a0" in graph_file: reference_file_netspa_a0 = config.GRAPH_FOLDER+network_context+"/"+graph_file

            if "TVA_f0" in graph_file:
                filenames_tva.append({config.GRAPH_FOLDER+network_context+"/"+graph_file:config.NETWORK_FOLDER+network_context+"/"+graph_file.split("_")[1].replace("graphml","json")})
            if "TVA_f0-a3" in graph_file: reference_file_tva_a3 = config.GRAPH_FOLDER+network_context+"/"+graph_file
            if "TVA_f0-a0" in graph_file: reference_file_tva_a0 = config.GRAPH_FOLDER+network_context+"/"+graph_file

            if "MULTI_f0" in graph_file:
                filenames_multi.append({config.GRAPH_FOLDER+network_context+"/"+graph_file:config.NETWORK_FOLDER+network_context+"/"+graph_file.split("_")[1].replace("graphml","json")})
            if "MULTI_f0-a3" in graph_file: reference_file_multi_a3 = config.GRAPH_FOLDER+network_context+"/"+graph_file
            if "MULTI_f0-a0" in graph_file: reference_file_multi_a0 = config.GRAPH_FOLDER+network_context+"/"+graph_file

        """
        TIME ANALYSIS
        """
        plot_generation_time(network_context)
        
        """
        SPACE ANALYSIS
        """
        space_complexity(filenames)
        # plot_space_bars(network_context)


        """
        ACCURACY ANALYSIS
        """
        risk_dict_netspa = accuracy_complexity(filenames_netspa, reference_file_netspa_a3)
        # plot_accuracy_distro(risk_dict_netspa)
        # plot_accuracy_paths(filenames_netspa, reference_file_netspa_a0)

        # risk_dict_tva = accuracy_complexity(filenames_tva, reference_file_tva_a3)
        # plot_accuracy_distro(risk_dict_tva)
        # plot_accuracy_paths(filenames_tva, reference_file_tva_a0)

        # risk_dict_multi = accuracy_complexity(filenames_multi, reference_file_multi_a3)
        # plot_accuracy_distro(risk_dict_multi)
        # plot_accuracy_paths(filenames_multi, reference_file_multi_a0)

        # plot_accuracy_bars(network_context)
    
    
    plot_generation_time_trend()



    