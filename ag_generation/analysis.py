import os, json, sys, os, csv
import pandas as pd
import numpy as np
from scipy import stats
import networkx as nx
import matplotlib.pyplot as plt
pd.options.mode.chained_assignment = None

sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir))
import config

def space_complexity(graph_filenames):
    for g_file in graph_filenames:
        G = nx.read_graphml(g_file)

        num_nodes = len(G.nodes())
        num_edges = len(G.edges())
        density = nx.density(G)

        num_components = nx.number_strongly_connected_components(G)
        
        indegree = G.in_degree()
        outdegree = G.out_degree()
        in_degrees_values = []
        for indeg in indegree:
            in_degrees_values.append(indeg[1])
        out_degrees_values = []
        for outdeg in outdegree:
            out_degrees_values.append(outdeg[1])

        closeness_centrality = nx.closeness_centrality(G)
        closeness_centr_values = []
        for k_cc in closeness_centrality.keys():
            closeness_centr_values.append(closeness_centrality[k_cc])

        aggregation_level = 0
        if "a0" in g_file: aggregation_level=0
        elif "a1" in g_file: aggregation_level=1
        elif "a2" in g_file: aggregation_level=2
        else: aggregation_level=3

        filter_level = 0
        if "f0" in g_file: filter_level=0
        elif "f1" in g_file: filter_level=1
        elif "f2" in g_file: filter_level=2
        else: filter_level=3

        subfolders =g_file.replace(".graphml","").split("/")
        network_type=subfolders[len(subfolders)-2]
        model=subfolders[len(subfolders)-1].split("_")[0]

        with open(config.ANALYSIS_SPACE_FILE, 'a', newline='') as fd:
            writer = csv.writer(fd)
            writer.writerow([
                network_type,model,filter_level,aggregation_level,
                num_nodes,num_edges,density,num_components,
                list(np.quantile(in_degrees_values,[0.25,0.5,0.75])) if len(in_degrees_values)>0 else None,
                list(np.quantile(out_degrees_values,[0.25,0.5,0.75])) if len(out_degrees_values)>0 else None,
                list(np.quantile(closeness_centr_values,[0.25,0.5,0.75])) if len(closeness_centr_values)>0 else None,
                sum(in_degrees_values)/len(in_degrees_values) if len(in_degrees_values)>0 else None,
                sum(out_degrees_values)/len(out_degrees_values) if len(out_degrees_values)>0 else None,
                sum(closeness_centr_values)/len(closeness_centr_values) if len(closeness_centr_values)>0 else None,
            ])

def accuracy_complexity(graph_filenames, a3_filename):
    
    G_base = nx.read_graphml(a3_filename)
    all_paths_distances = {x[0]:x[1] for x in nx.all_pairs_shortest_path_length(G_base)}
    entry_points = {}
    for src in all_paths_distances.keys():
        dict_dist = all_paths_distances[src]
        max_val = max(dict_dist.values())
        dst = [k for k,v in dict_dist.items() if v >= max_val]
        for target in dst:
            entry_points[(src,target)]=max_val
    entry_points = dict(sorted(entry_points.items(), key=lambda x:x[1], reverse=True))

    sources = []
    goals = []
    for entry in entry_points.keys():
        if "@" in entry[0] and "@" in entry[1]:
            sources.append(entry[0])
            goals.append(entry[1])

    for g_file in graph_filenames:
        G = nx.read_graphml(g_file)
        node_types = nx.get_node_attributes(G,"type")

        all_paths=[]
        for s in sources[:2]: 
            for t in goals[:2]:
                if s not in G.nodes() or t not in G.nodes(): 
                    print("wrong format: ", g_file)
                    break 
                current_paths = list(nx.all_simple_paths(G, source=s, target=t))
                for p in current_paths:
                    for no in p:
                        print(node_types[no])
                all_paths+=current_paths

        subfolders=g_file.replace(".graphml","").split("/")
        network_type=subfolders[len(subfolders)-2]
        model=subfolders[len(subfolders)-1].split("_")[0]

        aggregation_level = 0
        if "a0" in g_file: aggregation_level=0
        elif "a1" in g_file: aggregation_level=1
        elif "a2" in g_file: aggregation_level=2
        else: aggregation_level=3

        filter_level = 0
        if "f0" in g_file: filter_level=0
        elif "f1" in g_file: filter_level=1
        elif "f2" in g_file: filter_level=2
        else: filter_level=3

        with open(config.ANALYSIS_ACCURACY_FILE, 'a', newline='') as fd:
            writer = csv.writer(fd)
            writer.writerow([
                network_type,model,filter_level,aggregation_level,
                len(all_paths)
            ])

def plot_space_bars(stats_file):
    df = pd.read_csv(stats_file)
    
    grouped_by_network = df.groupby(by=["network"])
    for net_id, df_net in grouped_by_network:
        grouped_by_model = df_net.groupby(by=["model"])
        for model_id, df_model in grouped_by_model:
            df_model = df_model[df_model["filter"] == 0]

            aggregation_levels = list(set(df_model["aggregation"]))
            space_data = {
                'nodes': list(df_model["num_nodes"]),
                'edges': list(df_model["num_edges"]),
                'strong components': list(df_model["num_strong_components"]),
            }

            x = np.arange(len(aggregation_levels))  # the label locations
            width = 0.25  # the width of the bars
            multiplier = 0

            fig, ax = plt.subplots(layout='constrained')

            for key, val in space_data.items():
                offset = width * multiplier
                rects = ax.bar(x + offset, val, width, label=key)
                ax.bar_label(rects, padding=3)
                multiplier += 1

            # Add some text for labels, title and custom x-axis tick labels, etc.
            ax.set_xlabel('Aggregation Levels')
            ax.set_title(net_id.replace("_filter_aggregation","") + " - " + model_id)
            ax.set_xticks(x + width, aggregation_levels)
            ax.legend(loc='upper right')

            plt.savefig(config.PLOT_FOLDER+net_id+"_"+model_id+".png", bbox_inches='tight')
            plt.close()

if __name__ == "__main__":
    
    if not os.path.exists("analysis/"): os.mkdir("analysis/")
    if not os.path.exists(config.PLOT_FOLDER): os.mkdir(config.PLOT_FOLDER)
    
    # reset_space=False
    # if not os.path.exists(config.ANALYSIS_SPACE_FILE) or reset_space:
    #     with open(config.ANALYSIS_SPACE_FILE, 'w', newline='') as f:
    #         writer = csv.writer(f)
    #         writer.writerow(['network','model','filter','aggregation',
    #                          'num_nodes','num_edges','density',
    #                          'num_strong_components',
    #                          'indegree','outdegree','close_centrality',
    #                          'avg_indegree','avg_outdegree','avg_close_centrality'
    #                         ])
    
    reset_accuracy=True
    if not os.path.exists(config.ANALYSIS_ACCURACY_FILE) or reset_accuracy:
        with open(config.ANALYSIS_ACCURACY_FILE, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['network','model','filter','aggregation',
                             'num_paths'
                            ])

    for network_context in os.listdir(config.GRAPH_FOLDER):
        filenames=[]

        filenames_netspa=[]
        reference_file_netspa=""
        for graph_file in os.listdir(config.GRAPH_FOLDER+network_context):
            filenames.append(config.GRAPH_FOLDER+network_context+"/"+graph_file)
            
            if "NETSPA_f0" in graph_file:
                filenames_netspa.append(config.GRAPH_FOLDER+network_context+"/"+graph_file)
            if "NETSPA_f0-a3" in graph_file: reference_file_netspa = config.GRAPH_FOLDER+network_context+"/"+graph_file
        
        # space_complexity(filenames)
        accuracy_complexity(filenames_netspa, reference_file_netspa)
        break
    # plot_space_bars(config.ANALYSIS_SPACE_FILE)

    